{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from miscc.config import cfg, cfg_from_file\n",
    "from datasets import TextDataset\n",
    "from trainer import condGANTrainer as trainer\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "import pprint\n",
    "import datetime\n",
    "import dateutil.tz\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# dir_path = (os.path.abspath(os.path.join(os.path.realpath(__file__), './.')))\n",
    "# sys.path.append(dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class parse_args():\n",
    "    cfg_file='../code/cfg/bird_attn2.yml'\n",
    "    gpu_id=3\n",
    "    data_dir='../data/birds/'\n",
    "    manualSeed=1\n",
    "args = parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using config:\n",
      "{'B_VALIDATION': False,\n",
      " 'CONFIG_NAME': 'attn2',\n",
      " 'CUDA': True,\n",
      " 'DATASET_NAME': 'birds',\n",
      " 'DATA_DIR': '../data/birds/',\n",
      " 'GAN': {'B_ATTENTION': True,\n",
      "         'B_DCGAN': False,\n",
      "         'CONDITION_DIM': 100,\n",
      "         'DF_DIM': 64,\n",
      "         'GF_DIM': 32,\n",
      "         'R_NUM': 2,\n",
      "         'Z_DIM': 100},\n",
      " 'GPU_ID': 3,\n",
      " 'RNN_TYPE': 'LSTM',\n",
      " 'TEXT': {'CAPTIONS_PER_IMAGE': 10, 'EMBEDDING_DIM': 256, 'WORDS_NUM': 18},\n",
      " 'TRAIN': {'BATCH_SIZE': 20,\n",
      "           'B_NET_D': True,\n",
      "           'DISCRIMINATOR_LR': 0.0002,\n",
      "           'ENCODER_LR': 0.0002,\n",
      "           'FLAG': True,\n",
      "           'GENERATOR_LR': 0.0002,\n",
      "           'MAX_EPOCH': 600,\n",
      "           'NET_E': '../DAMSMencoders/bird/text_encoder50.pth',\n",
      "           'NET_G': '',\n",
      "           'RNN_GRAD_CLIP': 0.25,\n",
      "           'SMOOTH': {'GAMMA1': 4.0,\n",
      "                      'GAMMA2': 5.0,\n",
      "                      'GAMMA3': 10.0,\n",
      "                      'LAMBDA': 5.0},\n",
      "           'SNAPSHOT_INTERVAL': 50},\n",
      " 'TREE': {'BASE_SIZE': 64, 'BRANCH_NUM': 3},\n",
      " 'WORKERS': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/MyDataStor1/mmrl/MMRL/notebooks/miscc/config.py:104: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  yaml_cfg = edict(yaml.load(f))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "args = parse_args()\n",
    "if args.cfg_file is not None:\n",
    "    cfg_from_file(args.cfg_file)\n",
    "\n",
    "if args.gpu_id == -1:\n",
    "    cfg.CUDA = False\n",
    "else:\n",
    "    cfg.GPU_ID = args.gpu_id\n",
    "\n",
    "if args.data_dir != '':\n",
    "    cfg.DATA_DIR = args.data_dir\n",
    "    \n",
    "\n",
    "print('Using config:')\n",
    "pprint.pprint(cfg)\n",
    "\n",
    "if not cfg.TRAIN.FLAG:\n",
    "    args.manualSeed = 100\n",
    "elif args.manualSeed is None:\n",
    "    args.manualSeed = random.randint(1, 10000)\n",
    "random.seed(args.manualSeed)\n",
    "np.random.seed(args.manualSeed)\n",
    "torch.manual_seed(args.manualSeed)\n",
    "if cfg.CUDA:\n",
    "    torch.cuda.manual_seed_all(args.manualSeed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.datetime.now(dateutil.tz.tzlocal())\n",
    "timestamp = now.strftime('%Y_%m_%d_%H_%M_%S')\n",
    "output_dir = '../output/{0}_{1}_{2}'.format(cfg.DATASET_NAME, cfg.CONFIG_NAME, timestamp)\n",
    "\n",
    "split_dir, bshuffle = 'train', True\n",
    "if not cfg.TRAIN.FLAG:\n",
    "    # bshuffle = False\n",
    "    split_dir = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mshaikh2/anaconda3/envs/pytorch-gpu/lib/python3.7/site-packages/torchvision/transforms/transforms.py:210: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
      "  warnings.warn(\"The use of the transforms.Scale transform is deprecated, \" +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total filenames:  11788 001.Black_footed_Albatross/Black_Footed_Albatross_0046_18.jpg\n",
      "Load filenames from: ../data/birds//train/filenames.pickle (8855)\n",
      "Load filenames from: ../data/birds//test/filenames.pickle (2933)\n",
      "Load from:  ../data/birds/captions.pickle\n",
      "../data/birds/train\n",
      "../data/birds/train/class_info.pickle\n"
     ]
    }
   ],
   "source": [
    "# Get data loader\n",
    "imsize = cfg.TREE.BASE_SIZE * (2 ** (cfg.TREE.BRANCH_NUM - 1))\n",
    "image_transform = transforms.Compose([\n",
    "    transforms.Scale(int(imsize * 76 / 64)),\n",
    "    transforms.RandomCrop(imsize),\n",
    "    transforms.RandomHorizontalFlip()])\n",
    "dataset = TextDataset(cfg.DATA_DIR, split_dir,\n",
    "                      base_size=cfg.TREE.BASE_SIZE,\n",
    "                      transform=image_transform)\n",
    "assert dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(\n",
    "        dataset, batch_size=cfg.TRAIN.BATCH_SIZE,\n",
    "        drop_last=True, shuffle=bshuffle, num_workers=int(cfg.WORKERS))\n",
    "\n",
    "# Define models and go to train/evaluate\n",
    "algo = trainer(output_dir, dataloader, dataset.n_words, dataset.ixtoword)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pretrained model from  https://download.pytorch.org/models/inception_v3_google-1a9a5a14.pth\n",
      "Load image encoder from: ../DAMSMencoders/bird/image_encoder50.pth\n",
      "Load text encoder from: ../DAMSMencoders/bird/text_encoder50.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mshaikh2/anaconda3/envs/pytorch-gpu/lib/python3.7/site-packages/torch/nn/modules/rnn.py:51: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of netsD 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mshaikh2/anaconda3/envs/pytorch-gpu/lib/python3.7/site-packages/torch/nn/functional.py:1350: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/home/mshaikh2/anaconda3/envs/pytorch-gpu/lib/python3.7/site-packages/torch/nn/functional.py:2479: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "errD0: 0.55 errD1: 0.61 errD2: 1.17 \n",
      "g_loss0: 8.40 g_loss1: 10.51 g_loss2: 1.99 w_loss: 32.68 s_loss: 30.01 kl_loss: 0.01 \n",
      "errD0: 0.74 errD1: 0.76 errD2: 0.99 \n",
      "g_loss0: 8.94 g_loss1: 12.08 g_loss2: 2.39 w_loss: 23.33 s_loss: 25.20 kl_loss: 0.01 \n",
      "errD0: 0.24 errD1: 0.24 errD2: 0.47 \n",
      "g_loss0: 8.08 g_loss1: 16.08 g_loss2: 7.04 w_loss: 17.14 s_loss: 18.63 kl_loss: 0.01 \n",
      "errD0: 0.35 errD1: 0.61 errD2: 0.62 \n",
      "g_loss0: 8.16 g_loss1: 18.69 g_loss2: 9.09 w_loss: 20.21 s_loss: 19.19 kl_loss: 0.01 \n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "invalid index of a 0-dim tensor. Use tensor.item() to convert a 0-dim tensor to a Python number",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-2ae3d4189999>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstart_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFLAG\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0malgo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m'''generate images from pre-extracted embeddings'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/MyDataStor1/mmrl/MMRL/notebooks/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    319\u001b[0m                   Loss_D: %.2f Loss_G: %.2f Time: %.2fs'''\n\u001b[1;32m    320\u001b[0m                   % (epoch, self.max_epoch, self.num_batches,\n\u001b[0;32m--> 321\u001b[0;31m                      \u001b[0merrD_total\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrG_total\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m                      end_t - start_t))\n\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: invalid index of a 0-dim tensor. Use tensor.item() to convert a 0-dim tensor to a Python number"
     ]
    }
   ],
   "source": [
    "start_t = time.time()\n",
    "if cfg.TRAIN.FLAG:\n",
    "    algo.train()\n",
    "else:\n",
    "    '''generate images from pre-extracted embeddings'''\n",
    "    if cfg.B_VALIDATION:\n",
    "        algo.sampling(split_dir)  # generate images for the whole valid dataset\n",
    "    else:\n",
    "        gen_example(dataset.wordtoix, algo)  # generate images for customized captions\n",
    "end_t = time.time()\n",
    "print('Total time for training:', end_t - start_t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sigmoid(): argument 'input' (position 1) must be Tensor, not method",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-52c9bb4f04bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: sigmoid(): argument 'input' (position 1) must be Tensor, not method"
     ]
    }
   ],
   "source": [
    "torch.sigmoid(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch-gpu)",
   "language": "python",
   "name": "pytorch-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
